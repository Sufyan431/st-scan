{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0esyzRp6rmGV",
      "metadata": {
        "id": "0esyzRp6rmGV"
      },
      "source": [
        "## libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "34e8b9bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34e8b9bd",
        "outputId": "9ddf313b-1281-4d56-ec79-0ded18ba9c8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖLibraries Imported Successfully ....!!!\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# üìå 1. Importing Required Libraries\n",
        "# ================================\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import VGG19, ResNet101\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "\n",
        "print(f\"‚úÖLibraries Imported Successfully ....!!!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8Am6NxWCszPn",
      "metadata": {
        "id": "8Am6NxWCszPn"
      },
      "source": [
        "## Check the GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "wSXG_4zzsccp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSXG_4zzsccp",
        "outputId": "b8dfaa6a-5294-405e-b781-0b4ef7ad2e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå GPU is NOT available.\n"
          ]
        }
      ],
      "source": [
        "# ==================================\n",
        "# üìå 2. Checking GPU Availability\n",
        "# ==================================\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"‚úÖ GPU is available. Using device:\", device)\n",
        "else:\n",
        "    print(\"‚ùå GPU is NOT available.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dnlKz56vrwqF",
      "metadata": {
        "id": "dnlKz56vrwqF"
      },
      "source": [
        "## Connect to Google-Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "AUi4FbV2oWdj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUi4FbV2oWdj",
        "outputId": "80bb26f3-2b15-4e5e-c4b7-95bf12996dc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖSuccessfully loaded Google Drive.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "try:\n",
        "    # Mounting Google Drive to the Colab environment\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖSuccessfully loaded Google Drive.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùåGoogle Drive could not be loaded. Please try again: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "o-W7r2MlsCD9",
      "metadata": {
        "id": "o-W7r2MlsCD9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "853-txDYs4Ta",
      "metadata": {
        "id": "853-txDYs4Ta"
      },
      "source": [
        "## Extractall dataset in Google-Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e7ad09c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7ad09c7",
        "outputId": "d2e52ea0-0eab-4b76-fdfb-35a1ec37e092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset successfully extracted.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "try:\n",
        "    # Read the lung cancer dataset zip file from Google Drive\n",
        "    zip_path = \"/content/drive/MyDrive/Colab Notebooks/Augmented IQ-OTHNCCD lung cancer dataset.zip\"\n",
        "\n",
        "    # Open the zip file in read mode\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Extract the dataset to the /content directory\n",
        "        zip_ref.extractall(\"/content\")\n",
        "\n",
        "    print(\"‚úÖ Dataset successfully extracted.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Error: Zip file not found. Check the file path.\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"‚ùå Error: File is not a valid zip file or is corrupted.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An unexpected error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LWZZfo6ZxVvW",
      "metadata": {
        "id": "LWZZfo6ZxVvW"
      },
      "source": [
        "## \"Generator means dividing a large dataset into batches of a specified size.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "pqmMcYcCoZAb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqmMcYcCoZAb",
        "outputId": "69e43fa5-b939-4f6e-c768-498c0cc686c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2886 files belonging to 3 classes.\n",
            "Class Names: ‚úÖ ['Benign cases', 'Malignant cases', 'Normal cases']\n",
            "‚úÖ Data Elements Defined successfully...!\n",
            "\n",
            "Found 723 files belonging to 3 classes.\n",
            "Class Names: ‚úÖ ['Benign cases', 'Malignant cases', 'Normal cases']\n",
            "‚úÖ Data Elements Defined successfully...!\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    directory=\"/content/Augmented IQ-OTHNCCD lung cancer dataset/train\",  # Remove extra space\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256)\n",
        ")\n",
        "\n",
        "# Displaying class names\n",
        "print(\"Class Names: ‚úÖ\", train_dataset.class_names)\n",
        "print(\"‚úÖ Data Elements Defined successfully...!\")\n",
        "\n",
        "print()\n",
        "\n",
        "test_dataset =image_dataset_from_directory(\n",
        "    directory=\"/content/Augmented IQ-OTHNCCD lung cancer dataset/test\",  # Remove extra space\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256)\n",
        ")\n",
        "\n",
        "# Displaying class names\n",
        "print(\"Class Names: ‚úÖ\", test_dataset.class_names)\n",
        "print(\"‚úÖ Data Elements Defined successfully...!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "evTUeBtZ7Ywj",
      "metadata": {
        "id": "evTUeBtZ7Ywj"
      },
      "source": [
        "## Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "xsFrF2owo_6z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsFrF2owo_6z",
        "outputId": "5841f5ec-ab41-4be6-b2a8-253d3f140b6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖNormalization applied successfully!\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary layers from Keras\n",
        "from tensorflow.keras.layers import Rescaling\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "try:\n",
        "    # Creating a normalization layer using Rescaling\n",
        "    # Rescaling means scaling the pixel values from the range 0‚Äì255 to 0‚Äì1 by dividing by 255.\n",
        "    normalization_layer = Sequential([\n",
        "        Rescaling(1./255)  # Divide each pixel value by 255 to normalize images\n",
        "    ])\n",
        "\n",
        "    # Applying the normalization layer to the training dataset\n",
        "    # `map()` applies the normalization to each image in the dataset.\n",
        "    train_dataset = train_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "    # Applying the same normalization to the test dataset\n",
        "    # This ensures that both training and testing data are normalized the same way.\n",
        "    test_dataset = test_dataset.map(lambda x, y: (normalization_layer(x), y))\n",
        "\n",
        "    print(\"‚úÖNormalization applied successfully!\")\n",
        "except Exception as e:\n",
        "    # If an error occurs during the process, it will be caught here\n",
        "    print(f\"‚ùåNormalization is not Successfully please check the code: {e}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "st_scan",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
